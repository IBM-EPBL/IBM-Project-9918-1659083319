{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e5f6f4",
   "metadata": {},
   "source": [
    "## Importing ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb46189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e9824",
   "metadata": {},
   "source": [
    "## Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36024b8",
   "metadata": {},
   "source": [
    "##### Configuring image Data Generator Class\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54e8ba",
   "metadata": {},
   "source": [
    "###### Setting Parameter for Image Augmentation for training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e28d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a16d96",
   "metadata": {},
   "source": [
    "##### Image Data Augmentation for testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4220a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945decd",
   "metadata": {},
   "source": [
    "## Applying ImageDataGenerator functionality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fea8d75",
   "metadata": {},
   "source": [
    "##### Performing data augmentation to train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86799cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 742 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('train_set', target_size = (64,64), batch_size = 5, color_mode = 'rgb', class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b9f22",
   "metadata": {},
   "source": [
    "##### Performing data augmentation to test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ad5cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 197 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory('test_set', target_size = (64,64), batch_size = 5, color_mode = 'rgb', class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4d3c7",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8f25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb8f64",
   "metadata": {},
   "source": [
    "### Initializing the model by adding CNN layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "748983b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db198b01",
   "metadata": {},
   "source": [
    "### First convolution layer and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e47fabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89ab02",
   "metadata": {},
   "source": [
    "### Second convolution layer and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a38d94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245416f8",
   "metadata": {},
   "source": [
    "### Flattening the layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08410062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a8fa7",
   "metadata": {},
   "source": [
    "### Adding dense layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62c8f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dense(units=4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a55f2c",
   "metadata": {},
   "source": [
    "## Model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfbd8361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,604\n",
      "Trainable params: 813,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a350ecd",
   "metadata": {},
   "source": [
    "## Compiling the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11bbb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde96368",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c964a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRASANNA\\AppData\\Local\\Temp\\ipykernel_16000\\2997991227.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=x_train,steps_per_epoch=len(x_train),epochs=30,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "149/149 [==============================] - 75s 481ms/step - loss: 1.2354 - accuracy: 0.3989 - val_loss: 1.0837 - val_accuracy: 0.5888\n",
      "Epoch 2/30\n",
      "149/149 [==============================] - 32s 213ms/step - loss: 0.9091 - accuracy: 0.6011 - val_loss: 0.9331 - val_accuracy: 0.6497\n",
      "Epoch 3/30\n",
      "149/149 [==============================] - 32s 214ms/step - loss: 0.7744 - accuracy: 0.6739 - val_loss: 0.7638 - val_accuracy: 0.6650\n",
      "Epoch 4/30\n",
      "149/149 [==============================] - 32s 214ms/step - loss: 0.6780 - accuracy: 0.7170 - val_loss: 0.6413 - val_accuracy: 0.7614\n",
      "Epoch 5/30\n",
      "149/149 [==============================] - 32s 212ms/step - loss: 0.5892 - accuracy: 0.7763 - val_loss: 0.7562 - val_accuracy: 0.7462\n",
      "Epoch 6/30\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 0.5369 - accuracy: 0.8005 - val_loss: 1.2020 - val_accuracy: 0.5939\n",
      "Epoch 7/30\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.5541 - accuracy: 0.7844 - val_loss: 0.8689 - val_accuracy: 0.6751\n",
      "Epoch 8/30\n",
      "149/149 [==============================] - 37s 248ms/step - loss: 0.4694 - accuracy: 0.8275 - val_loss: 1.0487 - val_accuracy: 0.6701\n",
      "Epoch 9/30\n",
      "149/149 [==============================] - 40s 270ms/step - loss: 0.4669 - accuracy: 0.8248 - val_loss: 0.9499 - val_accuracy: 0.6802\n",
      "Epoch 10/30\n",
      "149/149 [==============================] - 35s 228ms/step - loss: 0.4245 - accuracy: 0.8437 - val_loss: 0.6931 - val_accuracy: 0.7614\n",
      "Epoch 11/30\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 0.3587 - accuracy: 0.8585 - val_loss: 0.9797 - val_accuracy: 0.7005\n",
      "Epoch 12/30\n",
      "149/149 [==============================] - 31s 207ms/step - loss: 0.3298 - accuracy: 0.8720 - val_loss: 0.7848 - val_accuracy: 0.7411\n",
      "Epoch 13/30\n",
      "149/149 [==============================] - 31s 207ms/step - loss: 0.3394 - accuracy: 0.8774 - val_loss: 0.7465 - val_accuracy: 0.7513\n",
      "Epoch 14/30\n",
      "149/149 [==============================] - 32s 215ms/step - loss: 0.2979 - accuracy: 0.8801 - val_loss: 0.6780 - val_accuracy: 0.7970\n",
      "Epoch 15/30\n",
      "149/149 [==============================] - 38s 258ms/step - loss: 0.2649 - accuracy: 0.8922 - val_loss: 0.7090 - val_accuracy: 0.7817\n",
      "Epoch 16/30\n",
      "149/149 [==============================] - 39s 258ms/step - loss: 0.2330 - accuracy: 0.9164 - val_loss: 0.9644 - val_accuracy: 0.7462\n",
      "Epoch 17/30\n",
      "149/149 [==============================] - 36s 240ms/step - loss: 0.2058 - accuracy: 0.9272 - val_loss: 0.7951 - val_accuracy: 0.7919\n",
      "Epoch 18/30\n",
      "149/149 [==============================] - 35s 234ms/step - loss: 0.2455 - accuracy: 0.9097 - val_loss: 0.8815 - val_accuracy: 0.7411\n",
      "Epoch 19/30\n",
      "149/149 [==============================] - 36s 243ms/step - loss: 0.2484 - accuracy: 0.9178 - val_loss: 0.7800 - val_accuracy: 0.7665\n",
      "Epoch 20/30\n",
      "149/149 [==============================] - 35s 233ms/step - loss: 0.2251 - accuracy: 0.9164 - val_loss: 1.4998 - val_accuracy: 0.6751\n",
      "Epoch 21/30\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 0.2450 - accuracy: 0.9016 - val_loss: 0.7876 - val_accuracy: 0.7970\n",
      "Epoch 22/30\n",
      "149/149 [==============================] - 32s 215ms/step - loss: 0.2398 - accuracy: 0.9151 - val_loss: 0.9285 - val_accuracy: 0.7563\n",
      "Epoch 23/30\n",
      "149/149 [==============================] - 35s 236ms/step - loss: 0.2004 - accuracy: 0.9326 - val_loss: 1.1595 - val_accuracy: 0.7208\n",
      "Epoch 24/30\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 0.1561 - accuracy: 0.9434 - val_loss: 0.9518 - val_accuracy: 0.7817\n",
      "Epoch 25/30\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 0.1401 - accuracy: 0.9569 - val_loss: 1.0260 - val_accuracy: 0.7614\n",
      "Epoch 26/30\n",
      "149/149 [==============================] - 32s 213ms/step - loss: 0.1310 - accuracy: 0.9474 - val_loss: 0.8950 - val_accuracy: 0.8122\n",
      "Epoch 27/30\n",
      "149/149 [==============================] - 32s 212ms/step - loss: 0.1797 - accuracy: 0.9367 - val_loss: 0.9011 - val_accuracy: 0.7614\n",
      "Epoch 28/30\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.0958 - accuracy: 0.9609 - val_loss: 0.9059 - val_accuracy: 0.7766\n",
      "Epoch 29/30\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.1075 - accuracy: 0.9650 - val_loss: 0.8920 - val_accuracy: 0.7919\n",
      "Epoch 30/30\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 0.0761 - accuracy: 0.9717 - val_loss: 1.2930 - val_accuracy: 0.7259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1deef065e70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=x_train,steps_per_epoch=len(x_train),epochs=30,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00167c",
   "metadata": {},
   "source": [
    "### Saving the model and writing to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "890d8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ibm_img_model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560fa24",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6101ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = load_model('ibm_img_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11db8946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72fc63",
   "metadata": {},
   "source": [
    "### Validating with new test inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9bb76",
   "metadata": {},
   "source": [
    "#### Input 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05ef656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Flood\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('test_set/Flood/1002.jpg',target_size=(64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "out=np.argmax(model.predict(x),axis=1)\n",
    "print(index[int(out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55917a",
   "metadata": {},
   "source": [
    "#### Input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a90ded26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "Wildfire\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('test_set/Wildfire/1066.jpg',target_size=(64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "out=np.argmax(model.predict(x),axis=1)\n",
    "print(index[int(out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35763c",
   "metadata": {},
   "source": [
    "#### Input 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30bdfed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Earthquake\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('test_set/Earthquake/1321.jpg',target_size=(64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "out=np.argmax(model.predict(x),axis=1)\n",
    "print(index[int(out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bd9d3",
   "metadata": {},
   "source": [
    "#### Input 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0707e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Cyclone\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('test_set/Cyclone/914.jpg',target_size=(64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "out=np.argmax(model.predict(x),axis=1)\n",
    "print(index[int(out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7465982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials = {\n",
    "    \"apikey\" : 'afZ5L-hF9buqV-upm3EyjWwKybgWaQqvg9sTSjJJkHlU',\n",
    "    \"url\" : \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ddea966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return (next(item for item in space['resources'] if item['entity'][\"name\"]==space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26f8b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space UID : 610a7f13-fc66-40b1-987c-a3a0ebd24ac3\n"
     ]
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client, 'project-deployments')\n",
    "print(\"Space UID : \"+ space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78e6c55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5436b29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab9e1b80-f2ce-592c-a7d2-4f2344f77194'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"default_py3.8\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.store_model(model='ibm_img_model.h5', meta_props={\n",
    "    client.repository.ModelMetaNames.NAME:\"image_modelling\",\n",
    "    client.repository.ModelMetaNames.TYPE:\"tensorflow_2.4\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_uid(model_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
